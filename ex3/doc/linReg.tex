\newif\ifvimbug
\vimbugfalse

\ifvimbug
\begin{document}
\fi

\exercise{Linear Regression}

In this exercise, you will use the dataset \texttt{linRegData.txt}, containing $150$ points in the format \texttt{<input variable, output variable>}. The input is generated by a sinusoid function, while the output is the joint trajectory of a compliant robotic arm. 
The first $N=20$ data points are the training set and the remainder are the testing set.

\begin{questions}

%----------------------------------------------

\begin{question}{Polynomial Features}{10}
Write the equation of the model and fit it with polynomial features. Using the Root Mean Square Error (RMSE) as a metric for the evaluation, select the complexity of the model (up to a 21st degree polynomial) by evaluating its performance the on testing data. Which is the best RMSE you achieve and what is the model complexity? Does it change if we evaluate our model on the training data? Comment your findings and plot the RMSE for each case (use two lines, one for evaluation on training data, one for evaluation on testing data).
For the estimation of the optimal parameters use a Ridge coefficient of $\lambda=10^{-6}$.

Using what you think is the best learned model from the previous point, show in a single plot the ground truth (full dataset) and the model prediction over it.
Attach snippets of your code showing how you generate polynomial features and how you fit the model.


\begin{answer}
In order to create polynomial features of degree n, the function exprepeat is used. It calculates the matrix $X$, based on the given vector
$x = (\begin{matrix}
x_k\\
\vdots\\
x_1\\
x_0\\
\end{matrix})$ as 
$X = (
\begin{matrix*}
	x_0^n & x_1^n & \hdots & x_k^n\\
	\vdots & \ddots & \hdots & \vdots\\
	x_0 & x_1 & \hdots & x_k\\
	1 & 1 & \hdots & 1
\end{matrix*}
)$
\lstinputlisting[language=Python, firstline= 5, lastline = 15]{../Code/31a.py}

The polynomial features are then used in polyregress to calculate the coefficients of the polynomial of degree n, according to the formula in the lecture: $w=(XX^T)^{-1}Xy$

\lstinputlisting[language=Python, firstline= 17, lastline = 24]{../Code/31a.py}

Based on these results, the polynomial is first evaluated at all available data points, using $y_{fit} = w^TX$. The RMSE is than calculated as $\sqrt{\sum_{n=0}^{N-1}\frac{ (y_{fit,n}-y_n)^2}{N}}$, where $N$ is the number of samples in the dataset. This is done separately for the test and training set.

\lstinputlisting[language=Python, firstline= 25, lastline = 28]{../Code/31a.py}

The resulting RMSE for train and test data are plotted in the follwing figure.

\centering \includegraphics[width=0.7\linewidth]{img/31a}

As the plot shows, the RMSE of the training set is always lower than the one of the test set. This is not surprising, since the regression is trying to minimize the error for the training set. The lowest RMSE for the test set is achieved by using a polynomial of degree 17. This polynomial is shown in the following figure.

\centering \includegraphics[width=0.7\linewidth]{img/31a2}

	
\end{answer}

\end{question}

%----------------------------------------------

\begin{question}{Gaussian Features}{4}
Now use Gaussian features. Each feature is a Gaussian distribution were the means are distributed linearly in $x \in[0,2]$ and the variance is set to $\sigma^2=0.02$. The features have to be normalized, i.e., they have to sum to one at every state. Using $N=20$ features generate a plot with the activation of each feature over time (i.e., plot the matrix $\Phi$). Attach a snippet of your code showing how to compute Gaussian features.

\begin{answer}
\centering \includegraphics[width=1.0\linewidth]{img/31b}\label{fig:gaussians}

\lstinputlisting[language=Python, firstline = 11]{../Code/31b.py}

\end{answer}

\end{question}

%----------------------------------------------

\begin{question}{Gaussian Features, Continued}{6}
Repeat the process of fitting the model using the Gaussian features from the previous question. Compare the RMSE on the testing data using $15 \ldots 40$ basis functions and plot the RMSE. Which number of basis functions has the best performance and what is the best RMSE? Use a Ridge coefficient of $\lambda=10^{-6}$.

\begin{answer}\end{answer}
The best RMSE is $0.015431$ using 29 basis functions. \\
\centering \includegraphics[width=1.0\linewidth]{img/31c_rmse}\label{fig:gaussians_rmse}

\end{question}

%----------------------------------------------

\begin{question}{Bayesian Linear Regression}{10}
Using Bayesian linear regression and polynomial features of 12th degree, plot the mean and the standard deviation of the predictive distribution for each case, using the first $N={10, 12, 16, 20, 50, 150}$ data points.
Discuss how the model uncertainty change with the amount of data points and the problem of overfitting with Bayesian linear regression. Use a prior $\sigma^2=0.0025$.

\begin{answer}
The uncertainty is getting lower the more data points we use for learning. This can be seen especially in the plot for $N=10$, where the area between data points is very uncertain, due to the lack of available information. However, the more points we have the less uncertain we are about our prediction. For infinite data-points the uncertainty would converge to zero.\\
Regarding overfitting the bayesian linear regression performs better than MLE, because instead of optimizing (which leads to a single solution) we are averaging over many different solutions, which will typically lead to better predictions.

\centering \includegraphics[width=1.0\linewidth]{img/31d_10} \\
\centering \includegraphics[width=1.0\linewidth]{img/31d_12} \\
\centering \includegraphics[width=1.0\linewidth]{img/31d_16} \\
\centering \includegraphics[width=1.0\linewidth]{img/31d_20} \\
\centering \includegraphics[width=1.0\linewidth]{img/31d_50} \\
\centering \includegraphics[width=1.0\linewidth]{img/31d_150}


\end{answer}
\end{question}

%----------------------------------------------

\begin{question}{Bayesian Linear Regression, Continued}{5}
How can we further reduce the uncertainty? Is it always a good practice?

\begin{answer}
In order to further reduce uncertainty we can use more data points. This is not always good practice, because using up to all data points defeats the purpose of a model for prediction.
\end{answer}
\end{question}

%----------------------------------------------

\begin{question}[bonus]{Cross Validation}{5}
So far, we have split our dataset in two sets: training data and testing data. Cross-validation is a more sophisticated approach for model selection. Discuss it and its variants, pointing out their pro and cons.
\end{question}

\begin{answer}
When the original dataset is simply split into training- and test-set has the drawback, that evaluations based on this approach tend to reflect the particular characteristics of the splits. One may use statistical sampling to get better results. There are two cross-validation strategies:\\
\textbf{k-fold cross-validation}: The data is divided into $k$ different chunks (of same size), which are each used once as the learning-set in $k$ runs. Validation takes place on the respective training-sets in each run.\\
This method can be improved by choosing the $k$ chunks in a way, that data-points are similarly distributed in all chunks. This is called \textbf{stratified k-fold cross-validation} and reduces the predictions variance. \\
\textbf{Leave-one-out validation}: The data is divided in $N$ chunks of data, one for each data-point. This results in $N$ runs, which can lead to severe runtimes. In addition a stratified version is not possible. Furthermore there are extreme cases, in which the leave-one-out validation can give faulty results.
\end{answer}

\end{questions}
